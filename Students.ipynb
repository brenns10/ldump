{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LDAP Dump Post-processing\n",
    "\n",
    "The file `ldump.py` includes functions for creating the LDAP dump files and combining them into a single `attributes.pkl` file. From there, I used this notebook to help me visualize, filter, and export the data in CSV. The results are probably not reproducible yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The shape of the data is one very long list of dicts, each dict representing key/value attributes that LDAP returned. Turning that directly into a dataframe gives us every single key as a column, and those who don't have a value for a column receive NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('attributes.pkl', 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "(above output not included for obvious reasons)\n",
    "\n",
    "## LDAP Attributes\n",
    "\n",
    "Here I wanted to look at what attributes are provided by LDAP, and how many of them area available for each user. This is by far the trickiest part of the LDAP import: determining which attributes are \"universal\" and which ones are missing for users that should be on the site. Additionally, how do we figure out whether an LDAP entry is for a student, faculty, or alum?  A summary of my findings is below (note that 278,000 entries are in the dump).\n",
    "\n",
    "- The uid (case ID), sn (last name), givenName (first name), cn (full name) fields are present for pretty much every entry. The mail-related fields are also pretty much universal.\n",
    "- The most useful field for determining the type of user seems to be `cwruEduPersonScopedAffiliation`. It only occurs for around 138,000 entries though. The other affiliation-related entries (first seen, last seen, expiration) are even less common. I have a suspicion that these fields only occur for users with the objectClass cwruEduPerson, which might make a good filter.\n",
    "- The `cwruEduEntryLastModified` seems pretty universal as well, and I later use that to order and filter users by how recently they were modified. The assumption is that recently modified users are more relevant (i.e. have been to case within a few years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "print_full(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Case ID Explorations\n",
    "\n",
    "The LDAP attribute values are provided in lists, even though many attributes are single-valued. We'll be seing a lot of this pattern, where we apply a lambda that grabs the first item from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.uid.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here I was examining the distribution of Case IDs. It appears that most are between 3 and 6 digits of length, although 7 is possible (and legitimate). There are three outliers - two of length 8 and one of length 46. I manually removed these three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uidstr = df.uid.apply(lambda x: x[0])\n",
    "uidstr.apply(len).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uidstr[174025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idlens = uidstr.apply(len)\n",
    "idlens.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idlens[idlens == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idlens[idlens == 46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uidstr[174025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.drop([174025, 162555, 162770])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cleanup and filtering\n",
    "\n",
    "Here begins the main segment of cleanup and filtering. In particular, I'm selecting a subset of the attributes I'm interested in (see below). Then, I'm making them all single valued. Finally, I'm filtering down to only users who have values for all of these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner = df[['uid', 'cn', 'sn', 'givenName', 'mail', 'cwruEduAccountAdded', 'cwruEduEntryLastModified', 'cwruEduPersonScopedAffiliation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.uid = cleaner.uid.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.loc[:, 'cn'] = cleaner.cn.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.loc[:, 'sn'] = cleaner.sn.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I think one of the rows had a NaN for a name somewhere, and thus I dropped it. Grossss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner = cleaner.drop(269654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.loc[:, 'givenName'] = cleaner.givenName.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.loc[:, 'cwruEduAccountAdded'] = cleaner.cwruEduAccountAdded.apply(lambda x: x[0][:8] if type(x) is list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaner.loc[:, 'cwruEduEntryLastModified'] = cleaner.cwruEduEntryLastModified.apply(lambda x: x[0][:8] if type(x) is list else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here's the filtering..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleanest = cleaner.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(cleanest.shape)\n",
    "cleanest = cleanest.sort_values('cwruEduAccountAdded')\n",
    "cleanest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I'm manually checking some IDs to see how everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleanest[cleanest.uid == 'hsc21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleanest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A blunt filtering mechanism: \"if you were modified since last year, you probably belong in the database.\"  Not sure if this is the flawed assumption, or if a previous filtering step was problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recent = cleanest[cleanest.cwruEduEntryLastModified > '20160000']\n",
    "recent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recent[recent.uid == 'exk92']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exporting\n",
    "\n",
    "Here I take the existing dataframe and prepare it (rename, drop, create columns as necessary) to be in the format expected out of the import CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export = recent.rename(columns={'uid': 'username', 'sn': 'last_name', 'givenName': 'first_name'})\n",
    "export = export.drop(['cn', 'mail', 'cwruEduAccountAdded', 'cwruEduEntryLastModified'], axis=1)\n",
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_department(affil):\n",
    "    if 'student@case.edu' in affil:\n",
    "        department = 'Student'\n",
    "    elif 'faculty@case.edu' in affil:\n",
    "        department = 'Faculty'\n",
    "    elif 'alum@case.edu' in affil:\n",
    "        department = 'Alumni'\n",
    "    else:\n",
    "        department = ''\n",
    "    return department\n",
    "\n",
    "export['department'] = export.cwruEduPersonScopedAffiliation.apply(compute_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export = export.drop(['cwruEduPersonScopedAffiliation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export['photo_url'] = 'https://placehold.it/100x100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export = export[['username', 'first_name', 'last_name', 'department', 'photo_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export.to_csv('employees.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Due to performance limitations on the CSV import process, I split it into three CSVs, hoping that I could do them each sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split = export.shape[0] // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export1 = export.iloc[0:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export2 = export.iloc[split:2 * split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export3 = export.iloc[2*split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export1.to_csv('employees1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export2.to_csv('employees2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "export3.to_csv('employees3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
